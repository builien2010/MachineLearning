{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer  \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docFile(file1):\n",
    "\n",
    "    #print(file1)\n",
    "    with open(file1, \"rb\") as f:\n",
    "        \n",
    "        contents = f.read()\n",
    "\n",
    "        contents = contents.decode('utf-8', 'ignore')\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    # Tạo mảng array từ file : tách từ bằng khoảng trắng\n",
    "    arrays = contents.split()\n",
    "    #print(\"B1: len = \", len(array))\n",
    "\n",
    "    # Loại bỏ các kí tự đặc biệt và số trong mỗi phần tử  trong mangr\n",
    "    array1 = []\n",
    "    stemmer = PorterStemmer()\n",
    "    for word in arrays:\n",
    "        word = word.lower() \n",
    "        word = re.sub(r'[^a-z]', '', word)\n",
    "        if(word) not in (stopwords.words('english')):\n",
    "            if( len(word) < 10 and len(word) > 2):\n",
    "                array1.append(stemmer.stem(word))\n",
    "    \n",
    "    tf = np.unique(array1, return_counts = True)[1].tolist()\n",
    "    value = np.unique(array1, return_counts = True)[0].tolist()\n",
    "\n",
    "    str = ' '.join(value)\n",
    "    \n",
    "\n",
    "    return str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path1 = \"/media/builien/Study/Data/20news-bydate/20news-bydate-train\"\n",
    "path2 = \"/media/builien/Study/Data/20news-bydate/20news-bydate-test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FJoin = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(path):\n",
    "    contents = \"\"\n",
    "    labels = \"\"\n",
    "\n",
    "    dirs = [FJoin(path, f) for f in os.listdir(path)]\n",
    "\n",
    "    for i in range(0,len(dirs)): \n",
    "        d = dirs[i]  \n",
    "        files = [FJoin(d, f) for f in os.listdir(d)]\n",
    "        for j in range(0,len(files)):\n",
    "        \n",
    "            s = docFile(files[j])\n",
    "            #print(str)\n",
    "            s = str(i) + \"<###>\" +  s + \"\\n\"\n",
    "            contents = contents + s\n",
    "            labels = labels + str(i) + \"\\n\"\n",
    "\n",
    "    return contents, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "contents_train, labels_train = solve(path1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"train.txt\", \"w+\")\n",
    "file.write(contents_train)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"labels_train.txt\", \"w+\")\n",
    "file.write(labels_train)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_test, labels_test = solve(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"test.txt\", \"w+\")\n",
    "file.write(contents_test)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"labels_test.txt\", \"w+\")\n",
    "file.write(labels_test)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = contents_train + contents_test\n",
    "file = open(\"all.txt\", \"w+\")\n",
    "file.write(contents)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_train + labels_test\n",
    "file = open(\"labels.txt\", \"w+\")\n",
    "file.write(labels)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
